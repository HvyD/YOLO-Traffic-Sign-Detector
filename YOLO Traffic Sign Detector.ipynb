{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Traffic Sign Detection System\n",
    "The Dataset if from [LISA: Laboratory For Intelligent & Safe Automobiles](http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html)\n",
    "\n",
    "\n",
    "_cite_ = Andreas MÃ¸gelmose, Mohan M. Trivedi, and Thomas B. Moeslund, \"Vision based Traffic Sign Detection and Analysis for Intelligent Driver Assistance Systems: Perspectives and Survey,\" IEEE Transactions on Intelligent Transportation Systems, 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import init\n",
    "from mxnet import gpu\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon import Block, HybridBlock\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet Load and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 43\n",
    "BATCH_SIZE = 4\n",
    "DATA_SHAPE = 512\n",
    "train_data = mx.image.ImageIter(\n",
    "   batch_size=BATCH_SIZE, label_width = 1,\n",
    "   data_shape=(3, DATA_SHAPE, DATA_SHAPE), \n",
    "   path_imgrec='./dataset/dataset.rec',  \n",
    "   path_imgidx='./dataset/dataset.idx',  \n",
    "   shuffle=True)\n",
    "\n",
    "\n",
    "batch = train_data.next()\n",
    "\n",
    "def get_label():\n",
    "    paths = glob.glob(\"data/scene-jpg/*.jpg\")\n",
    "    labels = nd.zeros((len(paths), NUM_CLASS+1, 5)) -1.\n",
    "    print(labels.shape)\n",
    "    gts = open(\"data/gt1.txt\",'r').read().split('\\n')[:-1]\n",
    "    for gt in gts:\n",
    "        line = gt.split(\";\")\n",
    "        idx = int(line[0].split(\".\")[0])\n",
    "        minx = float(line[1])\n",
    "        miny = float(line[2])\n",
    "        maxx = float(line[3])\n",
    "        maxy = float(line[4])\n",
    "        label = float(line[5])\n",
    "        labels[idx][int(label)] = [label, minx, miny, maxx, maxy]\n",
    "    return labels\n",
    "\n",
    "def get_signname():\n",
    "    signname_file = \"data/signnames.csv\"\n",
    "    with open(signname_file) as f:\n",
    "        f.readline() # \n",
    "        signnames = [row[1] for row in csv.reader(f)]\n",
    "    return signnames\n",
    "\n",
    "\n",
    "labels = get_label()\n",
    "signnames = get_signname()\n",
    "        \n",
    "for label in labels[1]:\n",
    "    if(label[0] >= 0):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_label = batch.label[0].asnumpy().astype(int)\n",
    "print(batch_label)\n",
    "\n",
    "fig,ax = plt.subplots(1, 4, figsize=(25,25))\n",
    "for i in range(4):\n",
    "    print(batch_label[i])\n",
    "    img = batch.data[0][i]\n",
    "    img = img.transpose((1, 2, 0))\n",
    "    img = img.clip(0,255).asnumpy() / 255\n",
    "    mul_label = labels[batch_label][i].asnumpy()\n",
    "    ax[i].imshow(img)\n",
    "    for box in mul_label:\n",
    "        sign = int(box[0])\n",
    "        if(sign < 0):\n",
    "            continue\n",
    "        minx = int(box[1] * DATA_SHAPE)\n",
    "        miny = int(box[2] * DATA_SHAPE)\n",
    "        maxx = int(box[3] * DATA_SHAPE)\n",
    "        maxy = int(box[4] * DATA_SHAPE)\n",
    "        print(sign, signnames[sign], minx, miny, maxx, maxy)\n",
    "        rect = plt.Rectangle((minx, miny), maxx-minx, maxy-miny,fill=False, edgecolor='red', linewidth=3)\n",
    "        ax[i].add_patch(rect)\n",
    "        ax[i].text(minx, miny-2, '{:s}'.format(signnames[sign]),fontsize=12, color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Only Look Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_center(xy):\n",
    "    \"\"\"Given x, y prediction after sigmoid(), convert to relative coordinates (0, 1) on image.\"\"\"\n",
    "    b, h, w, n, s = xy.shape\n",
    "    offset_y = nd.tile(nd.arange(0, h, repeat=(w * n * 1), ctx=xy.context).reshape((1, h, w, n, 1)), (b, 1, 1, 1, 1))\n",
    "    # print(offset_y[0].asnumpy()[:, :, 0, 0])\n",
    "    offset_x = nd.tile(nd.arange(0, w, repeat=(n * 1), ctx=xy.context).reshape((1, 1, w, n, 1)), (b, h, 1, 1, 1))\n",
    "    # print(offset_x[0].asnumpy()[:, :, 0, 0])\n",
    "    x, y = xy.split(num_outputs=2, axis=-1)\n",
    "    x = (x + offset_x) / w\n",
    "    y = (y + offset_y) / h\n",
    "    return x, y\n",
    "\n",
    "def transform_size(wh, anchors):\n",
    "    \"\"\"Given w, h prediction after exp() and anchor sizes, convert to relative width/height (0, 1) on image\"\"\"\n",
    "    b, h, w, n, s = wh.shape\n",
    "    aw, ah = nd.tile(nd.array(anchors, ctx=wh.context).reshape((1, 1, 1, -1, 2)), (b, h, w, 1, 1)).split(num_outputs=2, axis=-1)\n",
    "    w_pred, h_pred = nd.exp(wh).split(num_outputs=2, axis=-1)\n",
    "    w_out = w_pred * aw / w\n",
    "    h_out = h_pred * ah / h\n",
    "    return w_out, h_out\n",
    "\n",
    "def yolo2_forward(x, num_class, anchor_scales):\n",
    "    \"\"\"Transpose/reshape/organize convolution outputs.\"\"\"\n",
    "    stride = num_class + 5\n",
    "    # transpose and reshape, 4th dim is the number of anchors\n",
    "    x = x.transpose((0, 2, 3, 1))\n",
    "    x = x.reshape((0, 0, 0, -1, stride))\n",
    "    # now x is (batch, m, n, stride), stride = num_class + 1(object score) + 4(coordinates)\n",
    "    # class probs\n",
    "    cls_pred = x.slice_axis(begin=0, end=num_class, axis=-1)\n",
    "    # object score\n",
    "    score_pred = x.slice_axis(begin=num_class, end=num_class + 1, axis=-1)\n",
    "    score = nd.sigmoid(score_pred)\n",
    "    # center prediction, in range(0, 1) for each grid\n",
    "    xy_pred = x.slice_axis(begin=num_class + 1, end=num_class + 3, axis=-1)\n",
    "    xy = nd.sigmoid(xy_pred)\n",
    "    # width/height prediction\n",
    "    wh = x.slice_axis(begin=num_class + 3, end=num_class + 5, axis=-1)\n",
    "    # convert x, y to positions relative to image\n",
    "    x, y = transform_center(xy)\n",
    "    # convert w, h to width/height relative to image\n",
    "    w, h = transform_size(wh, anchor_scales)\n",
    "    # cid is the argmax channel\n",
    "    cid = nd.argmax(cls_pred, axis=-1, keepdims=True)\n",
    "    # convert to corner format boxes\n",
    "    half_w = w / 2\n",
    "    half_h = h / 2\n",
    "    left = nd.clip(x - half_w, 0, 1)\n",
    "    top = nd.clip(y - half_h, 0, 1)\n",
    "    right = nd.clip(x + half_w, 0, 1)\n",
    "    bottom = nd.clip(y + half_h, 0, 1)\n",
    "    output = nd.concat(*[cid, score, left, top, right, bottom], dim=4)\n",
    "    return output, cls_pred, score, nd.concat(*[xy, wh], dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner2center(boxes, concat=True):\n",
    "    \"\"\"Convert left/top/right/bottom style boxes into x/y/w/h format\"\"\"\n",
    "    left, top, right, bottom = boxes.split(axis=-1, num_outputs=4)\n",
    "    x = (left + right) / 2\n",
    "    y = (top + bottom) / 2\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "    if concat:\n",
    "        last_dim = len(x.shape) - 1\n",
    "        return nd.concat(*[x, y, width, height], dim=last_dim)\n",
    "    return x, y, width, height\n",
    "\n",
    "def center2corner(boxes, concat=True):\n",
    "    \"\"\"Convert x/y/w/h style boxes into left/top/right/bottom format\"\"\"\n",
    "    x, y, w, h = boxes.split(axis=-1, num_outputs=4)\n",
    "    w2 = w / 2\n",
    "    h2 = h / 2\n",
    "    left = x - w2\n",
    "    top = y - h2\n",
    "    right = x + w2\n",
    "    bottom = y + h2\n",
    "    if concat:\n",
    "        last_dim = len(left.shape) - 1\n",
    "        return nd.concat(*[left, top, right, bottom], dim=last_dim)\n",
    "    return left, top, right, bottom\n",
    "\n",
    "def yolo2_target(scores, boxes, labels, anchors, ignore_label=-1, thresh=0.5):\n",
    "    \"\"\"Generate training targets given predictions and labels.\"\"\"\n",
    "    b, h, w, n, _ = scores.shape\n",
    "    anchors = np.reshape(np.array(anchors), (-1, 2))\n",
    "    #scores = nd.slice_axis(outputs, begin=1, end=2, axis=-1)\n",
    "    #boxes = nd.slice_axis(outputs, begin=2, end=6, axis=-1)\n",
    "    gt_boxes = nd.slice_axis(labels, begin=1, end=5, axis=-1)\n",
    "    target_score = nd.zeros((b, h, w, n, 1), ctx=scores.context)\n",
    "    target_id = nd.ones_like(target_score, ctx=scores.context) * ignore_label\n",
    "    target_box = nd.zeros((b, h, w, n, 4), ctx=scores.context)\n",
    "    sample_weight = nd.zeros((b, h, w, n, 1), ctx=scores.context)\n",
    "    for b in range(len(labels)):\n",
    "        # find the best match for each ground-truth\n",
    "        label = labels[b].asnumpy()\n",
    "        valid_label = label[np.where(label[:, 0] > -0.5)[0], :]\n",
    "        # shuffle because multi gt could possibly match to one anchor, we keep the last match randomly\n",
    "        np.random.shuffle(valid_label)\n",
    "        for l in valid_label:\n",
    "            gx, gy, gw, gh = (l[1] + l[3]) / 2, (l[2] + l[4]) / 2, l[3] - l[1], l[4] - l[2]\n",
    "            ind_x = int(gx * w)\n",
    "            ind_y = int(gy * h)\n",
    "            tx = gx * w - ind_x\n",
    "            ty = gy * h - ind_y\n",
    "            gw = gw * w\n",
    "            gh = gh * h\n",
    "            # find the best match using width and height only, assuming centers are identical\n",
    "            intersect = np.minimum(anchors[:, 0], gw) * np.minimum(anchors[:, 1], gh)\n",
    "            ovps = intersect / (gw * gh + anchors[:, 0] * anchors[:, 1] - intersect)\n",
    "            best_match = int(np.argmax(ovps))\n",
    "            target_id[b, ind_y, ind_x, best_match, :] = l[0]\n",
    "            target_score[b, ind_y, ind_x, best_match, :] = 1.0\n",
    "            tw = np.log(gw / anchors[best_match, 0])\n",
    "            th = np.log(gh / anchors[best_match, 1])\n",
    "            target_box[b, ind_y, ind_x, best_match, :] = mx.nd.array([tx, ty, tw, th])\n",
    "            sample_weight[b, ind_y, ind_x, best_match, :] = 1.0\n",
    "            # print('ind_y', ind_y, 'ind_x', ind_x, 'best_match', best_match, 't', tx, ty, tw, th, 'ovp', ovps[best_match], 'gt', gx, gy, gw/w, gh/h, 'anchor', anchors[best_match, 0], anchors[best_match, 1])\n",
    "    return target_id, target_score, target_box, sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO2Output(HybridBlock):\n",
    "    def __init__(self, num_class, anchor_scales, **kwargs):\n",
    "        super(YOLO2Output, self).__init__(**kwargs)\n",
    "        assert num_class > 0, \"number of classes should > 0, given {}\".format(num_class)\n",
    "        self._num_class = num_class\n",
    "        assert isinstance(anchor_scales, (list, tuple)), \"list or tuple of anchor scales required\"\n",
    "        assert len(anchor_scales) > 0, \"at least one anchor scale required\"\n",
    "        for anchor in anchor_scales:\n",
    "            assert len(anchor) == 2, \"expected each anchor scale to be (width, height), provided {}\".format(anchor)\n",
    "        self._anchor_scales = anchor_scales\n",
    "        out_channels = len(anchor_scales) * (num_class + 1 + 4)\n",
    "        with self.name_scope():\n",
    "            self.output = nn.Conv2D(out_channels, 1, 1)\n",
    "\n",
    "    def hybrid_forward(self, F, x, *args):\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import metric\n",
    "\n",
    "class LossRecorder(mx.metric.EvalMetric):\n",
    "    \"\"\"LossRecorder is used to record raw loss so we can observe loss directly\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super(LossRecorder, self).__init__(name)\n",
    "\n",
    "    def update(self, labels, preds=0):\n",
    "        \"\"\"Update metric with pure loss\n",
    "        \"\"\"\n",
    "        for loss in labels:\n",
    "            if isinstance(loss, mx.nd.NDArray):\n",
    "                loss = loss.asnumpy()\n",
    "            self.sum_metric += loss.sum()\n",
    "            self.num_inst += 1\n",
    "\n",
    "obj_loss = LossRecorder('objectness_loss')\n",
    "cls_loss = LossRecorder('classification_loss')\n",
    "box_loss = LossRecorder('box_refine_loss')\n",
    "\n",
    "sce_loss = gluon.loss.SoftmaxCrossEntropyLoss(from_logits=False)\n",
    "l1_loss = gluon.loss.L1Loss()\n",
    "\n",
    "positive_weight = 5.0\n",
    "negative_weight = 0.1\n",
    "class_weight = 1.0\n",
    "box_weight = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(archor_scales):\n",
    "    pretrained = vision.get_model('resnet18_v1', pretrained=True, root='/home/lsq/Carnd1/my/Traffic-Sign-Detection').features\n",
    "    net = nn.HybridSequential()\n",
    "    for i in range(len(pretrained) - 2):\n",
    "        net.add(pretrained[i])\n",
    "\n",
    "    # use 44 classes, 1 as dummy class, otherwise softmax won't work\n",
    "    predictor = YOLO2Output(NUM_CLASS, archor_scales)\n",
    "    predictor.initialize()\n",
    "    net.add(predictor)\n",
    "    return net\n",
    "\n",
    "START_EPOCH = 400\n",
    "END_EPOCH = 500\n",
    "# anchor scales, try adjust it yourself\n",
    "scales = [[3.3004, 3.59034],[9.84923, 8.23783]]\n",
    "net = get_net(scales)\n",
    "ctx = gpu(0)\n",
    "net.load_params('params/yolo2_%d.params'%START_EPOCH)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(),'sgd', {'learning_rate': 7e-4, 'wd': 5e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def train():\n",
    "    for epoch in range(START_EPOCH, END_EPOCH):\n",
    "        # reset data iterators and metrics\n",
    "        train_data.reset()\n",
    "        cls_loss.reset()\n",
    "        obj_loss.reset()\n",
    "        box_loss.reset()\n",
    "        tic = time.time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            x = batch.data[0].as_in_context(ctx)\n",
    "            batch_label = batch.label[0].asnumpy().astype(int)\n",
    "            y = labels[batch_label].as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                x = net(x)\n",
    "                output, cls_pred, score, xywh = yolo2_forward(x, NUM_CLASS, scales)\n",
    "                with autograd.pause():\n",
    "                    tid, tscore, tbox, sample_weight = yolo2_target(score, xywh, y, scales, thresh=0.5)\n",
    "                # losses\n",
    "                loss1 = sce_loss(cls_pred, tid, sample_weight * class_weight)\n",
    "                score_weight = nd.where(sample_weight > 0,\n",
    "                                        nd.ones_like(sample_weight) * positive_weight,\n",
    "                                        nd.ones_like(sample_weight) * negative_weight)\n",
    "                loss2 = l1_loss(score, tscore, score_weight)\n",
    "                loss3 = l1_loss(xywh, tbox, sample_weight * box_weight)\n",
    "                loss = loss1 + loss2 + 5*loss3\n",
    "            loss.backward()\n",
    "            trainer.step(BATCH_SIZE)\n",
    "            # update metrics\n",
    "            cls_loss.update(loss1)\n",
    "            obj_loss.update(loss2)\n",
    "            box_loss.update(loss3)\n",
    "\n",
    "        print('Epoch %2d, train %s %.5f, %s %.5f, %s %.5f time %.1f sec' % (\n",
    "            epoch, *cls_loss.get(), *obj_loss.get(), *box_loss.get(), time.time()-tic))\n",
    "\n",
    "    net.save_params('params/yolo2_%d.params' % END_EPOCH)\n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_gt():\n",
    "    labels = [[] for i in range(50)]\n",
    "    width = 1360\n",
    "    height = 800\n",
    "    gts = open(\"dataset/test_gt.txt\",'r').read().split('\\n')[:-1]\n",
    "    for gt in gts:\n",
    "        line = gt.split(\";\")\n",
    "        idx = int(line[0].split(\".\")[0])\n",
    "        x1 = float(line[1]) / width\n",
    "        y1 = float(line[2]) / height\n",
    "        x2 = float(line[3]) / width\n",
    "        y2 = float(line[4]) / height\n",
    "        label = int(line[5])\n",
    "        labels[idx].append([label, x1, y1, x2, y2])\n",
    "    return labels\n",
    "\n",
    "def cal_cate_gt(gt_list):\n",
    "    cate_gt = [0 for i in range(NUM_CLASS)]\n",
    "    for gt in gt_list:\n",
    "        for label in gt:\n",
    "            cate_gt[label[0]] += 1\n",
    "    return cate_gt\n",
    "\n",
    "test_gt = get_test_gt()\n",
    "cate_gt = cal_cate_gt(test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\"Takes an image and apply preprocess\"\"\"\n",
    "    # swap BGR to RGB\n",
    "    image = image[:, :, (2, 1, 0)]\n",
    "    # convert to float before subtracting mean\n",
    "    image = image.astype(np.float32)\n",
    "    # subtract mean\n",
    "    image -= 128.\n",
    "    # organize as [batch-channel-height-width]\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = image[np.newaxis, :]\n",
    "    # convert to ndarray\n",
    "    image = nd.array(image)\n",
    "    return image\n",
    "\n",
    "def load_net():\n",
    "    pretrained = vision.get_model('resnet18_v1', pretrained=True, ctx=gpu(0), root='/home/lsq/Carnd1/my/Traffic-Sign-Detection').features\n",
    "    net = nn.HybridSequential()\n",
    "    for i in range(len(pretrained) - 2):\n",
    "        net.add(pretrained[i])\n",
    "\n",
    "    predictor = YOLO2Output(NUM_CLASS, scales)\n",
    "    predictor.initialize(ctx=gpu(0))\n",
    "    net.add(predictor)\n",
    "    net.load_params('params/yolo2_400.params')\n",
    "    return net\n",
    "\n",
    "def predict(net, x):\n",
    "    x = net(x)\n",
    "    output, cls_prob, score, xywh = yolo2_forward(x, NUM_CLASS, scales)\n",
    "    return nd.contrib.box_nms(output.reshape((0, -1, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, out, thresh=0.5):\n",
    "    mpl.rcParams['figure.figsize'] = (10,10)\n",
    "    pens = dict()\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    for det in out:\n",
    "        cid = int(det[0])\n",
    "        if cid < 0:\n",
    "            continue\n",
    "        score = det[1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        if cid not in pens:\n",
    "            pens[cid] = (random.random(), random.random(), random.random())\n",
    "        scales = [img.shape[1], img.shape[0]] * 2\n",
    "        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].clip(0,1).tolist(), scales)]\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, \n",
    "                             edgecolor=pens[cid], linewidth=3)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = signnames[cid]\n",
    "        plt.gca().text(xmin, ymin-2, '{:d},{:s},{:.3f}'.format(cid, text, score),\n",
    "                       bbox=dict(facecolor=pens[cid], alpha=0.5),\n",
    "                       fontsize=12, color='white')\n",
    "    plt.show()\n",
    "\n",
    "index = random.randint(0, len(test_gt))\n",
    "print(index)\n",
    "index = 49\n",
    "image = cv2.imread('dataset/512-test/'+ str(index).zfill(5) +'.jpg')\n",
    "x = preprocess(image)\n",
    "# print(x)\n",
    "net = load_net()\n",
    "out = predict(net, x.as_in_context(ctx))\n",
    "\n",
    "for pred in out[0]:\n",
    "    if pred[1] > 0.5:\n",
    "        print(pred)\n",
    "    \n",
    "for label in labels[index]:\n",
    "    if(label[0] >= 0):\n",
    "        print(label)\n",
    "display(image[:, :, (2, 1, 0)], out[0].asnumpy(), thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
